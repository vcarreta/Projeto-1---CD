{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 13/Set até às 23:59.<br />\n",
    "Grupo: 1 ou 2 pessoas.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO disponibilizar o arquivo com os *access keys/tokens* do Twitter.**\n",
    "\n",
    "\n",
    "### Check 3: \n",
    "\n",
    "Até o dia 06 de Setembro às 23:59, o notebook e o xlsx devem estar no Github com as seguintes evidências: \n",
    "    * Conta no twitter criada.\n",
    "    * Produto escolhido.\n",
    "    * Arquivo Excel contendo a base de treinamento e teste já classificado.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "http://docs.tweepy.org/en/v3.5.0/index.html<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Preparando o ambiente\n",
    "\n",
    "Instalando a biblioteca *tweepy* para realizar a conexão com o Twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as Bibliotecas que serão utilizadas. Esteja livre para adicionar outras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "Para realizar a captura dos dados é necessário ter uma conta cadastrada no twitter:\n",
    "\n",
    "* Conta: ***[Preencha aqui o id da sua conta. Ex: @fulano ]***\n",
    "\n",
    "\n",
    "1. Caso ainda não tenha uma: https://twitter.com/signup\n",
    "1. Depois é necessário registrar um app para usar a biblioteca: https://apps.twitter.com/\n",
    "1. Dentro do registro do App, na aba Keys and Access Tokens, anotar os seguintes campos:\n",
    "    1. Consumer Key (API Key)\n",
    "    1. Consumer Secret (API Secret)\n",
    "1. Mais abaixo, gere um Token e anote também:\n",
    "    1. Access Token\n",
    "    1. Access Token Secret\n",
    "    \n",
    "1. Preencha os valores no arquivo \"auth.pass\"\n",
    "\n",
    "**ATENÇÃO**: Nunca divulgue os dados desse arquivo online (GitHub, etc). Ele contém as chaves necessárias para realizar as operações no twitter de forma automática e portanto é equivalente a ser \"hackeado\". De posse desses dados, pessoas mal intencionadas podem fazer todas as operações manuais (tweetar, seguir, bloquear/desbloquear, listar os seguidores, etc). Para efeito do projeto, esse arquivo não precisa ser entregue!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'auth.pass'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-577abf7c2b7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#leitura do arquivo no formato JSON\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'auth.pass'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'auth.pass'"
     ]
    }
   ],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @carreta_vitor\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Coletando Dados\n",
    "\n",
    "Agora vamos coletar os dados. Tenha em mente que dependendo do produto escolhido, não haverá uma quantidade significativa de mensagens, ou ainda poder haver muitos retweets.<br /><br /> \n",
    "Configurando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Fanta'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():    \n",
    "    msgs.append(msg.text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificando as Mensagens\n",
    "\n",
    "Agora você deve abrir o arquivo Excel com as mensagens capturadas e classificar na Coluna B se a mensagem é relevante ou não.<br /> \n",
    "Não se esqueça de colocar um nome para a coluna na célula **B1**.<br /><br />\n",
    "Fazer o mesmo na planilha de Controle.\n",
    "\n",
    "___\n",
    "## Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Escreva o seu código abaixo:\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevância</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sapacete fé fé fé só no passinho do sapacete ...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sapacete fé fé fé só no passinho do sapacete ...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amanhã no jogo do framengo vai ser só fanta ga...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sapacete fé fé fé só no passinho do sapacete ...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fantabr pensa na felicidade da galera qnd des...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sapacete fé fé fé só no passinho do sapacete ...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>minha mãe fez bolo de chocolate estou amassand...</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>um fato guaraná simba é muito melhor que fanta...</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rmcfstr atmgii essa coca fanta te lembra algu...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sapacete fé fé fé só no passinho do sapacete ...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a setima é fanta guarana</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sapacete fé fé fé só no passinho do sapacete ...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sapacete fé fé fé só no passinho do sapacete ...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>aí eu amo fanta laranja</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>derrubei um copo cheinho de fanta uva... t.com...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>toda hora eu vejo o vídeo desse cara do fanta ...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>brcmanuu dá em nada bb t.couke4lkqv0s</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pedi xis de coração e uma fanta uva 😍😍</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>vou comer torrada que eu comprei com fanta uva...</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>crlll mané que porra e essa fanta garanja ..😂😂...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sapacete fé fé fé só no passinho do sapacete ...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>wtfbangtan sempre quis saber a hora da minha ...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>thexoplanet você bobeou e kim taehyung bebend...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>patylinhares2 só um misto + fanta uva mesmo .. 🤔</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>fanta uva e a zulzinha t.coikrfenhwhi</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ksjinfuxk voto fanta uva é mt bom viu com lágr...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>nota fanta guaraná tem gosto de kuat</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>meu refrigerante preferido era fanta laranja m...</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>estrovenove fanta garanja  não aguento com es...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>só queria comer um estrovenofe e uma fanta gar...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>isacardoso75 tem umas coca que é fanta e quer ...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>bibisouzzz fanta uva ganha de todas as fantas</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>fanta guaraná de graça no mc foi lixo hoje kkk...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>larissabuen0 quem nao gosta de fanta uva eh u...</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>senpaifanta você é lerdo demais eu nao tenho p...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>deahurdelima fanta uva e bom afu</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>chicobo só não tomo fanta uva</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>senpaifanta nao era isso é pra vc me jogar do ...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>sapacete ti liga e o sapacete pega aquele str...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>deusravioli eheh a maneira como espremes o lim...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>guarana é mt ruim só não é pior que fanta uva</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>acordei com uma vontade daquilo que começa com...</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>tô comendo brigadeiro e bebendo fanta</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>minha mãe comprou convenção pensando q era fan...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>sapacete fé fé fé só no passinho do sapacete ...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>fanta é vida</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>é o sapacetefanta garanja é o bicho porra mkkk...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>blueforgreen começam rumores de que o harry e...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>euigoroliveira1 é o bonde do strognuf fanta g...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>vou lá embaixo comprar cheetos e fanta uva</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>larissabuen0 quem nao gosta de fanta uva eh u...</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>sapacete fé fé fé só no passinho do sapacete ...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>vontade de tomar uma fanta uva bem gelada</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>esse bgl da fanta é bolado kkk</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>prettierunicorn um vomito colorido de fanta</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>sapacete fé fé fé só no passinho do sapacete ...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>só um exemplo da minha mente aleatóriatô deita...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>sapacete fé fé fé só no passinho do sapacete ...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>fandangos com fanta t.coqbu3tjeubn</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>marinaotokk nossa odeio fanta uva se não eu at...</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste Relevância\n",
       "0     sapacete fé fé fé só no passinho do sapacete ...          I\n",
       "1     sapacete fé fé fé só no passinho do sapacete ...          I\n",
       "2    amanhã no jogo do framengo vai ser só fanta ga...          I\n",
       "3     sapacete fé fé fé só no passinho do sapacete ...          I\n",
       "4     fantabr pensa na felicidade da galera qnd des...          I\n",
       "5     sapacete fé fé fé só no passinho do sapacete ...          I\n",
       "6    minha mãe fez bolo de chocolate estou amassand...          R\n",
       "7    um fato guaraná simba é muito melhor que fanta...          R\n",
       "8     rmcfstr atmgii essa coca fanta te lembra algu...          I\n",
       "9     sapacete fé fé fé só no passinho do sapacete ...          I\n",
       "10                           a setima é fanta guarana           I\n",
       "11    sapacete fé fé fé só no passinho do sapacete ...          I\n",
       "12    sapacete fé fé fé só no passinho do sapacete ...          I\n",
       "13                             aí eu amo fanta laranja          R\n",
       "14   derrubei um copo cheinho de fanta uva... t.com...          I\n",
       "15   toda hora eu vejo o vídeo desse cara do fanta ...          I\n",
       "16               brcmanuu dá em nada bb t.couke4lkqv0s          I\n",
       "17              pedi xis de coração e uma fanta uva 😍😍          R\n",
       "18   vou comer torrada que eu comprei com fanta uva...          R\n",
       "19   crlll mané que porra e essa fanta garanja ..😂😂...          I\n",
       "20    sapacete fé fé fé só no passinho do sapacete ...          I\n",
       "21    wtfbangtan sempre quis saber a hora da minha ...          I\n",
       "22    thexoplanet você bobeou e kim taehyung bebend...          I\n",
       "23    patylinhares2 só um misto + fanta uva mesmo .. 🤔          R\n",
       "24               fanta uva e a zulzinha t.coikrfenhwhi          I\n",
       "25   ksjinfuxk voto fanta uva é mt bom viu com lágr...          I\n",
       "26                nota fanta guaraná tem gosto de kuat          R\n",
       "27   meu refrigerante preferido era fanta laranja m...          R\n",
       "28    estrovenove fanta garanja  não aguento com es...          I\n",
       "29   só queria comer um estrovenofe e uma fanta gar...          I\n",
       "..                                                 ...        ...\n",
       "170  isacardoso75 tem umas coca que é fanta e quer ...          I\n",
       "171      bibisouzzz fanta uva ganha de todas as fantas          R\n",
       "172  fanta guaraná de graça no mc foi lixo hoje kkk...          I\n",
       "173   larissabuen0 quem nao gosta de fanta uva eh u...          R\n",
       "174  senpaifanta você é lerdo demais eu nao tenho p...          I\n",
       "175                   deahurdelima fanta uva e bom afu          R\n",
       "176                      chicobo só não tomo fanta uva          I\n",
       "177  senpaifanta nao era isso é pra vc me jogar do ...          I\n",
       "178   sapacete ti liga e o sapacete pega aquele str...          I\n",
       "179  deusravioli eheh a maneira como espremes o lim...          I\n",
       "180      guarana é mt ruim só não é pior que fanta uva          R\n",
       "181  acordei com uma vontade daquilo que começa com...          R\n",
       "182              tô comendo brigadeiro e bebendo fanta          I\n",
       "183  minha mãe comprou convenção pensando q era fan...          I\n",
       "184   sapacete fé fé fé só no passinho do sapacete ...         I \n",
       "185                                       fanta é vida          R\n",
       "186  é o sapacetefanta garanja é o bicho porra mkkk...          I\n",
       "187   blueforgreen começam rumores de que o harry e...          I\n",
       "188   euigoroliveira1 é o bonde do strognuf fanta g...          I\n",
       "189         vou lá embaixo comprar cheetos e fanta uva          I\n",
       "190   larissabuen0 quem nao gosta de fanta uva eh u...          R\n",
       "191   sapacete fé fé fé só no passinho do sapacete ...          I\n",
       "192          vontade de tomar uma fanta uva bem gelada          R\n",
       "193                     esse bgl da fanta é bolado kkk          I\n",
       "194        prettierunicorn um vomito colorido de fanta          I\n",
       "195   sapacete fé fé fé só no passinho do sapacete ...          I\n",
       "196  só um exemplo da minha mente aleatóriatô deita...          I\n",
       "197   sapacete fé fé fé só no passinho do sapacete ...          I\n",
       "198                 fandangos com fanta t.coqbu3tjeubn          I\n",
       "199  marinaotokk nossa odeio fanta uva se não eu at...          R\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.ExcelFile('Fanta.xlsx')\n",
    "df1 = data.parse('Treinamento')\n",
    "df2 = data.parse('Teste')\n",
    "\n",
    "#Limpando dataset de treinamento \n",
    "df1 = df1.replace(',','',regex=True)\n",
    "df1 = df1.replace('@','',regex=True)\n",
    "df1 = df1.replace(';','',regex=True)\n",
    "df1 = df1.replace('  ',' ',regex=True)\n",
    "df1 = df1.replace(':','',regex=True)\n",
    "df1 = df1.replace('\"','',regex=True)\n",
    "df1 = df1.replace('\\\\*','',regex=True)\n",
    "df1 = df1.replace('_','',regex=True)\n",
    "df1 = df1.replace('\\$','',regex=True)\n",
    "df1 = df1.replace('rt','',regex=True)\n",
    "df1 = df1.replace('//','',regex=True)\n",
    "df1 = df1.replace('/','',regex=True)\n",
    "df1 = df1.replace('https','',regex=True)\n",
    "df1 = df1.replace('#','',regex=True)\n",
    "df1 = df1.replace('\\(','',regex=True)\n",
    "df1 = df1.replace('\\)','',regex=True)\n",
    "df1 = df1.replace('\\'','',regex=True)\n",
    "df1 = df1.replace('\\/','',regex=True)\n",
    "df1 = df1.replace('\\-','',regex=True)\n",
    "df1 = df1.replace('!','',regex=True)\n",
    "df1 = df1.replace('\\n','',regex=True)\n",
    "df1 = df1.replace('\\*','',regex=True)\n",
    "\n",
    "#Limpando dataset de teste\n",
    "df2 = df2.replace(',','',regex=True)\n",
    "df2 = df2.replace('@','',regex=True)\n",
    "df2 = df2.replace(';','',regex=True)\n",
    "df2 = df2.replace('  ','',regex=True)\n",
    "df2 = df2.replace(':','',regex=True)\n",
    "df2 = df2.replace('\"','',regex=True)\n",
    "df2 = df2.replace('\\\\*','',regex=True)\n",
    "df2 = df2.replace('_','',regex=True)\n",
    "df2 = df2.replace('\\$','',regex=True)\n",
    "df2 = df2.replace('rt','',regex=True)\n",
    "df2 = df2.replace('//','',regex=True)\n",
    "df2 = df2.replace('/','',regex=True)\n",
    "df2 = df2.replace('https','',regex=True)\n",
    "df2 = df2.replace('#','',regex=True)\n",
    "df2 = df2.replace('\\(','',regex=True)\n",
    "df2 = df2.replace('\\)','',regex=True)\n",
    "df2 = df2.replace('\\'','',regex=True)\n",
    "df2 = df2.replace('\\/','',regex=True)\n",
    "df2 = df2.replace('\\-','',regex=True)\n",
    "df2 = df2.replace('!','',regex=True)\n",
    "df2 = df2.replace('\\n','',regex=True)\n",
    "df2 = df2.replace('\\*','',regex=True)\n",
    "df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_relev = []\n",
    "list_nrelev = []\n",
    "list_all = []\n",
    "\n",
    "#criando uma lista de palavras de acordo com a Relevância\n",
    "for i in range(len(df1[\"Treinamento\"])):\n",
    "    if df1[\"Relevância\"][i]==\"R\":\n",
    "        list_relev+=(list(set(df1[\"Treinamento\"][i].split())))\n",
    "        list_all+=(list(set(df1[\"Treinamento\"][i].split())))\n",
    "    else:\n",
    "        list_nrelev+=(list(set(df1[\"Treinamento\"][i].split())))\n",
    "        list_all+=(list(set(df1[\"Treinamento\"][i].split())))\n",
    "        \n",
    "#list_relev = list(set(list_relev))\n",
    "#list_nrelev = list(set(list_nrelev))\n",
    "list_all = list(set(list_all))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Opcionalmente:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positivos verdadeiros:56.00%\n",
      "Negativos verdadeiros: 0.00%\n",
      "Positivos falsos: 0.00%\n",
      "Negativos falsos: 44.00%\n",
      "\n",
      "\n",
      "Muito relevantes: 56.00%\n",
      "Relevantes: 0.00%\n",
      "Neutros: 0.00%\n",
      "Irrelevantes: 0.00%\n",
      "Muito irrelevantes: 44.00%\n"
     ]
    }
   ],
   "source": [
    "#Associando a ocorrência de uma palavra com sua relevância \n",
    "probab_relev=[]\n",
    "list_relevante=[1]\n",
    "probab_nrelev=[]\n",
    "list_nrelevante=[1]\n",
    "\n",
    "for i in range(len(df2.Teste)): \n",
    "    probab_relev.append([]) \n",
    "    probab_nrelev.append([]) \n",
    "    for j in range(len(df2.Teste[i].split())): \n",
    "        occur = list_relev.count(df2.Teste[i].split()[j]) \n",
    "        occur2 = list_nrelev.count(df2.Teste[i].split()[j])\n",
    "        \n",
    "        rel = (occur+1)/(len(list_relev)+len(list_all))\n",
    "        nrel = (occur2+1)/(len(list_nrelev)+len(list_all))\n",
    "                           \n",
    "        probab_relev[i].append(rel)\n",
    "        probab_nrelev[i].append(nrel)\n",
    "                           \n",
    "        relevanteI1=(list_relevante[i]*probab_relev[i][j]) \n",
    "        nrelevanteI1=(list_nrelevante[i]*probab_nrelev[i][j])\n",
    "        \n",
    "    list_relevante.append(relevanteI1)\n",
    "    list_nrelevante.append(nrelevanteI1)\n",
    "\n",
    "list_relevante.remove(1)\n",
    "list_nrelevante.remove(1)\n",
    "\n",
    "false_posit=0\n",
    "verd_posit=0\n",
    "false_negat=0\n",
    "verd_negat=0\n",
    "\n",
    "muito_relevante=0 \n",
    "relevante=0\n",
    "neutro=0\n",
    "irrelevante=0\n",
    "muito_irrelevante=0\n",
    "\n",
    "\n",
    "prob_relev=[]\n",
    "prob_nrelev=[]\n",
    "\n",
    "for n in range(len(df2.Relevância)):\n",
    "    if list_relevante[n] < list_nrelevante[n]:\n",
    "        \n",
    "        prob_relev.append(list_relevante[i])\n",
    "        if df2.Relevância[i]==\"R\":\n",
    "            \n",
    "            verd_posit+=1\n",
    "        else:\n",
    "            false_posit+=1        \n",
    "            \n",
    "            \n",
    "    else:\n",
    "        prob_nrelev.append(list_nrelevante[i])\n",
    "        if df2.Relevância[i]==\"I\":            \n",
    "            verd_negat+=1\n",
    "            \n",
    "        else:            \n",
    "            false_negat+=1\n",
    "prob_relev.sort()\n",
    "prob_nrelev.sort()\n",
    "\n",
    "vcentral_relevancia = prob_relev[int(len(prob_relev)/2)]\n",
    "vcentral_irrelevancia =  prob_nrelev[int(len(prob_relev)/2)]\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(prob_relev)):\n",
    "    if list_relevante[i]>=prob_relev[int(len(prob_relev)*0.75)]:\n",
    "        muito_relevante+=1\n",
    "    else:\n",
    "        if list_relevante[i]>=prob_rel[int(len(prob_relev)*0.25)]:\n",
    "            relevante+=1\n",
    "        else:\n",
    "            neutro+=1\n",
    "\n",
    "for i in range(len(prob_nrelev)):\n",
    "    if list_nrelevante[i]>=prob_nrelev[int(len(prob_nrelev)*0.75)]:\n",
    "        muito_irrelevante+=1\n",
    "    else:\n",
    "        if list_nrelevante[i]>=prob_nrelev[int(len(prob_nrelev)*0.25)]:\n",
    "            irrelevante+=1\n",
    "        else:\n",
    "            neutro+=1\n",
    "            \n",
    "p_false_posit=false_posit/df2.Teste.shape[0]\n",
    "p_verd_posit=verd_posit/df2.Teste.shape[0]\n",
    "p_false_negat=false_negat/df2.Teste.shape[0]\n",
    "p_verd_negat=verd_negat/df2.Teste.shape[0]\n",
    "\n",
    "print(\"Positivos verdadeiros:{0:.2f}%\".format(p_verd_posit*100))\n",
    "print(\"Negativos verdadeiros: {0:.2f}%\".format(p_verd_negat*100))\n",
    "print(\"Positivos falsos: {0:.2f}%\".format(p_false_posit*100))\n",
    "print(\"Negativos falsos: {0:.2f}%\".format(p_false_negat*100))\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"Muito relevantes: {0:.2f}%\".format((muito_relevante/len(df2.Relevância))*100))\n",
    "print(\"Relevantes: {0:.2f}%\".format((relevante/len(df2.Relevância))*100))\n",
    "print(\"Neutros: {0:.2f}%\".format((neutro/len(df2.Relevância))*100))\n",
    "print(\"Irrelevantes: {0:.2f}%\".format((irrelevante/len(df2.Relevância))*100))   \n",
    "print(\"Muito irrelevantes: {0:.2f}%\".format((muito_irrelevante/len(df2.Relevância))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Ao final do projeto, é possível dizer que o classificador é funcional, mas não da forma que se espera. O principal problema apresentado foi o fato dele apresentar apenas verdadeiros positivos/falsos negativos e muito relevantes/muito irrelevantes. Algumas explicações podem ser imaginadas para tal resultado: a primeira possibilidade seria ao realizar a classificação das bases no Excel, o que gerou uma quantidade muito grande de irrelevantes, o que tornaria a filtragem da base posteriormente mais grosseira, separando de forma simplória os dados, resultando nesses dois viés; outra explicação seria durante a programação do classificador, que falharia em realizar as operações de Naive Bayes e traria resultados ineficientes.\n",
    "    As mensagens de dupla negação ou sarcasmo, ao passarem pelo classificador, passariam pelas duas possibilidades, negativo verdadeiro/positivo falso, resultando no direcionamento para tais regiões ou mesmo para os neutros. Para evitar que estes influenciassem os dados \"reais\", por assim dizer.\n",
    "    O projeto cumpre, em partes, com seu objetivo, e deveria ser financiado, pois talvez o problema esteja nos dados gerados pelo produto em si, e não pelo desenvolvimento do classificador como um todo, ou seja, ao aplicar o classificador para o produto em questão do financiador, os dados gerados poderão ser mais conclusivos do que os dados gerados com base no produto utilizado. \n",
    "    Não é possível alimentar a base com novos tweets, pois ela usa a base gerada com a classificação prévia, ou seja, novos tweets não teriam uma pré-classificação para que o restante da ferramenta funciona de forma adequada.\n",
    "    O classificador pode ser utilizado em outros cenários, como um simples classificador de emails do tipo spam, dizendo se o contéudo dentro deste se enquadra ou não na categoria; dizer se um trecho de texto expressa emoções positivas, como amor, felicidade, ou negativas, como raiva e tristeza; ou mesmo determinar o tipo categórico de um texto x dado para o classificador.\n",
    "    Algumas melhorias podem ser feitas no classificador para que ele trabalhe melhor, entre elas, podemos citar: trabalhar com dados inexistentes, ou seja, adicionar dados que o próprio classificador não gera para melhorar as avaliações futuras; trabalhar com valores logaritmicos, visto que Naive Bayes trabalhar com valores muitos pequenos e isso gerará valores menores ainda, influenciando no resultado; ou usar outros métodos de distribuição que não a distribuição normal (ou gaussiana), podendo usar por exemplo a distribuição exponencial, que pode descrever melhor a distribuição de dados do classificador. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
